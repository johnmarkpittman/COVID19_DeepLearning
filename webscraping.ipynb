{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def gatherData(url):\n",
    "    url = url\n",
    "    html = requests.get(\n",
    "                url,\n",
    "                allow_redirects=False,\n",
    "                headers={\"User-Agent\": \"waybackpack\"},\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "    soup = BeautifulSoup(html.text, 'html')\n",
    "    totalItems = soup.find_all(class_ = 'state-wrap')\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"state\",\"area\",\"population\",\"date\",\"type\"])\n",
    "\n",
    "    for item in totalItems: \n",
    "\n",
    "        if item.find_all(class_ =\"l-place\"):\n",
    "            state = item.h3.text\n",
    "\n",
    "            for place in item.find_all(class_ = \"place-wrap\"):\n",
    "\n",
    "                date = place.find(class_ =\"l-date\").extract().text\n",
    "                population = place.find(class_ =\"l-population\").extract().text\n",
    "                area = place.find(class_ =\"l-place\").text\n",
    "                type = place.find(class_ =\"l-order\").text\n",
    "\n",
    "                dict = {'state': state, 'area': area, 'population': population,'date':date,'type':type}\n",
    "\n",
    "                df = df.append(dict, ignore_index=True)\n",
    "        else:\n",
    "            date = item.find(class_ =\"l-date\").extract().text\n",
    "            population = item.find(class_ =\"l-population\").extract().text\n",
    "            area = \"ALL\"\n",
    "            type = item.find(class_ =\"l-order\").text\n",
    "            state = item.h3.text\n",
    "\n",
    "            dict = {'state': state, 'area': area, 'population': population,'date':date,'type':type}\n",
    "            df = df.append(dict, ignore_index=True)\n",
    "\n",
    "    # Reformat some of the columns\n",
    "    df['population'] = df['population'].str.replace(\"About \",\"\")\n",
    "    df['date'] = df['date'].str.replace(\", effective \",\"\")\n",
    "    df['state'] = df['state'].str.strip()\n",
    "    df['area'] = df['area'].str.strip()\n",
    "\n",
    "    # Make date a date-time column\n",
    "    conditions = [\n",
    "    (df['date'].str.contains('..-')),\n",
    "    (df['date'].str.contains('^.-',regex=True)),\n",
    "    (df['date'].str.contains('March ')),\n",
    "    (df['date'].str.contains('April '))]\n",
    "    choices = [\"2020-03-\" + df['date'].str[0:2], \"2020-04-0\"+df[\"date\"].str[0], \"2020-03-\" + df[\"date\"].str[6:8],\"2020-04-0\" + df[\"date\"].str[6:7]]\n",
    "    df['date'] = np.select(conditions, choices)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0324 = gatherData(\"https://web.archive.org/web/20200324041533/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0325 = gatherData(\"https://web.archive.org/web/20200325184603/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0326 = gatherData(\"https://web.archive.org/web/20200326002332/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0327 = gatherData(\"https://web.archive.org/web/20200327003315/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0328 = gatherData(\"https://web.archive.org/web/20200328020115/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0329 = gatherData(\"https://web.archive.org/web/20200329000754/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0331 = gatherData(\"https://web.archive.org/web/20200331015116/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0402 = gatherData(\"https://web.archive.org/web/20200402134943/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0403 = gatherData(\"https://web.archive.org/web/20200403221428/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0407 = gatherData(\"https://web.archive.org/web/20200407140353/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0420 = gatherData(\"https://web.archive.org/web/20200421023813/https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")\n",
    "df_0423 = gatherData(\"https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_0324,df_0325,df_0326,df_0327,df_0328,df_0329,df_0331,df_0402,df_0403,df_0407,df_0420,df_0423])\n",
    "df_final.drop_duplicates().query('date !=0').to_csv(\"shelterinplace.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda7c09497a89f74b7988b290ea6a632478"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}